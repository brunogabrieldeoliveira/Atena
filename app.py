import streamlit as st
import os
from dotenv import load_dotenv

from langchain_openai import ChatOpenAI
from langchain_core.prompts import ChatPromptTemplate
from langchain_core.runnables import RunnablePassthrough

from langchain_community.document_loaders import FileSystemBlobLoader
from langchain_community.document_loaders.generic import GenericLoader
from langchain_community.document_loaders.parsers import PyPDFParser

from langchain_openai import OpenAIEmbeddings
from langchain_community.vectorstores import FAISS

# carregar variaveis de ambiente do aruqivo .env
_= load_dotenv()

# carrego modelo de linguagem
llm= ChatOpenAI(                # input cache  output
    model= "gpt-4o-mini",       # $0.15 $0.075 $0.60
    # model= "gpt-3.5-turbo",   # $0.50 $0.000 $1.50   
)

# carrego template prompt
rag_template= """
VocÃª Ã© um analista profissional do mercado financeiro.
Seu trabalho Ã© analisar o resultados das empresas por meio dos relatÃ³rios disponibilizados
pelas empresas e passÃ¡-los para o cliente de forma clara e objetiva.
Contexto: {context}
Pergunta do cliente: {question}
"""

# carrego o modelo do vetor
embeddings= OpenAIEmbeddings(   
    model="text-embedding-3-small",     # $0.02
    #model="text-embedding-ada-002",     # $0.10
    #model="text-embedding-3-large",     # $0.13
)

# sidebar

# obtendo arquivos para analise
with st.sidebar: 

    uploaded_file = st.file_uploader(
        "Entre com um documento para anÃ¡lise", 
        type=("pdf"),
        accept_multiple_files= True
    )
    # obtendo o contexto
    if len(uploaded_file) > 0:

        print("msn-1")
        print("\n")    
        print(uploaded_file[0])
        print("\n")          
        #print(uploaded_file[0].name)
        #print("\n")              
        #print(uploaded_file[1].name)
        #print("\n")
        
        # lendo varios arquivos
        loader = GenericLoader(
            blob_loader=FileSystemBlobLoader(
                path="./",
                glob="*.pdf",
            ),
            blob_parser=PyPDFParser(),  
        )

        # carregando os documentos
        documents= loader.load()

        #embeddings= OpenAIEmbeddings(   
        #    model="text-embedding-3-small",     # $0.02
        #    #model="text-embedding-ada-002",     # $0.10
        #    #model="text-embedding-3-large",     # $0.13
        #)

        # vetorizando os documentos
        vectorstore= FAISS.from_documents(documents, embeddings)
        retriever= vectorstore.as_retriever()
        

# body

# titulo
st.title("ðŸ“œ Atena") 
st.caption("ðŸš€ Chatbot para anÃ¡lise documentos!")

if "messages" not in st.session_state:
    st.session_state["messages"] = [{"role": "assistant", "content": "How can I help you?"}]

# obtendo a pergunta
question = st.text_input(
    "",
    placeholder="Pergunte qualquer coisa sobre o documento",
    disabled=not uploaded_file
)

if (len(uploaded_file) > 0) and question != "":
    
    # definindo o prompt
    prompt= ChatPromptTemplate.from_template(rag_template)
    chain= (
        {"context": retriever, "question": RunnablePassthrough()}
        | prompt
        | llm
    )

    # obtendo respota
    response= chain.invoke(question)
    
    msg = response.content
    st.session_state.messages.append({"role": "assistant", "content": msg})
    st.chat_message("assistant").write(msg)



